{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "petitions_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roiei/ml_study/blob/master/petitions_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvlOmq6RjeSa"
      },
      "source": [
        "# 2.1 크롤링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS1mqlLTjeSf"
      },
      "source": [
        "[크롤링]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBf8fqWtjeSg",
        "outputId": "876b26de-448c-4ac5-dc0a-c114bf7f973c"
      },
      "source": [
        "print('a')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLtvqjwLjeSi"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup \n",
        "import time\n",
        "\n",
        "\n",
        "result = pd.DataFrame()\n",
        "\n",
        "for i in range(584274, 595226):\n",
        "    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\n",
        " \n",
        "    response = requests.get(URL)\n",
        "    print(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vfYy2PuzjeSj",
        "outputId": "6e858322-b1e0-47c0-ccbb-40b9759a152b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup \n",
        "import time\n",
        "\n",
        "print('start')\n",
        "result = pd.DataFrame()\n",
        "\n",
        "start = 584274\n",
        "nums = 595226 - start\n",
        "\n",
        "for i in range(start, 595226):\n",
        "    print('before get')\n",
        "    URL = \"http://www1.president.go.kr/petitions/\"+str(i)\n",
        "    response = requests.get(URL)\n",
        "    #print(response, URL)\n",
        "    print('.')\n",
        "    html = response.text                                   \n",
        "    soup = BeautifulSoup(html, 'html.parser')           \n",
        "\n",
        "    title = soup.find('h3', class_='petitionsView_title')\n",
        "    count = soup.find('span', class_='counter')           \n",
        "\n",
        "    for content in soup.select('div.petitionsView_write > div.View_write'):\n",
        "        content                                         \n",
        "\n",
        "    a=[]\n",
        "    for tag in soup.select('ul.petitionsView_info_list > li'): \n",
        "        a.append(tag.contents[1])\n",
        "\n",
        "    if len(a) != 0:\n",
        "        df1=pd.DataFrame({ 'start' : [a[1]],                \n",
        "                           'end' : [a[2]],                     \n",
        "                           'category' :  [a[0]],               \n",
        "                           'count' : [count.text],             \n",
        "                           'title': [title.text],              \n",
        "                           'content': [content.text.strip()[0:13000]]                              \n",
        "                         })\n",
        "\n",
        "        result=pd.concat([result, df1])                        \n",
        "        result.index = np.arange(len(result)) \n",
        "    \n",
        "    if len(result) > 0:\n",
        "        print('data len = ', len(result))\n",
        "\n",
        "    if i % 60 == 0:                                        \n",
        "        print(\"Sleep 90seconds. Count:\" + str(i)           \n",
        "              +\",  Local Time:\"+ time.strftime('%Y-%m-%d', time.localtime(time.time()))\n",
        "              +\" \"+ time.strftime('%X', time.localtime(time.time()))\n",
        "              +\",  Data Length:\"+ str(len(result)))        \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "before get\n",
            ".\n",
            "data len =  1\n",
            "before get\n",
            ".\n",
            "data len =  2\n",
            "before get\n",
            ".\n",
            "data len =  3\n",
            "before get\n",
            ".\n",
            "data len =  4\n",
            "before get\n",
            ".\n",
            "data len =  5\n",
            "before get\n",
            ".\n",
            "data len =  6\n",
            "before get\n",
            ".\n",
            "data len =  7\n",
            "Sleep 90seconds. Count:584280,  Local Time:2021-09-08 13:19:44,  Data Length:7\n",
            "before get\n",
            ".\n",
            "data len =  8\n",
            "before get\n",
            ".\n",
            "data len =  9\n",
            "before get\n",
            ".\n",
            "data len =  10\n",
            "before get\n",
            ".\n",
            "data len =  11\n",
            "before get\n",
            ".\n",
            "data len =  12\n",
            "before get\n",
            ".\n",
            "data len =  13\n",
            "before get\n",
            ".\n",
            "data len =  14\n",
            "before get\n",
            ".\n",
            "data len =  15\n",
            "before get\n",
            ".\n",
            "data len =  16\n",
            "before get\n",
            ".\n",
            "data len =  17\n",
            "before get\n",
            ".\n",
            "data len =  18\n",
            "before get\n",
            ".\n",
            "data len =  19\n",
            "before get\n",
            ".\n",
            "data len =  20\n",
            "before get\n",
            ".\n",
            "data len =  21\n",
            "before get\n",
            ".\n",
            "data len =  22\n",
            "before get\n",
            ".\n",
            "data len =  23\n",
            "before get\n",
            ".\n",
            "data len =  24\n",
            "before get\n",
            ".\n",
            "data len =  25\n",
            "before get\n",
            ".\n",
            "data len =  26\n",
            "before get\n",
            ".\n",
            "data len =  27\n",
            "before get\n",
            ".\n",
            "data len =  28\n",
            "before get\n",
            ".\n",
            "data len =  29\n",
            "before get\n",
            ".\n",
            "data len =  30\n",
            "before get\n",
            ".\n",
            "data len =  31\n",
            "before get\n",
            ".\n",
            "data len =  32\n",
            "before get\n",
            ".\n",
            "data len =  33\n",
            "before get\n",
            ".\n",
            "data len =  34\n",
            "before get\n",
            ".\n",
            "data len =  35\n",
            "before get\n",
            ".\n",
            "data len =  36\n",
            "before get\n",
            ".\n",
            "data len =  37\n",
            "before get\n",
            ".\n",
            "data len =  38\n",
            "before get\n",
            ".\n",
            "data len =  39\n",
            "before get\n",
            ".\n",
            "data len =  40\n",
            "before get\n",
            ".\n",
            "data len =  41\n",
            "before get\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ChunkedEncodingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 16: b''",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# This includes IncompleteRead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Connection broken: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-57fb49f24900>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before get'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mURL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://www1.president.go.kr/petitions/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(response, URL)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mContentDecodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZfJue1tjeSk"
      },
      "source": [
        "[크롤링 데이터 확인]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj8d4MK2jeSl"
      },
      "source": [
        "print(result.shape)\n",
        "\n",
        "df = result\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R4U_7U6jeSn"
      },
      "source": [
        "[데이터 엑셀로 저장]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7WWf03GEjeSo"
      },
      "source": [
        "df.to_csv('data/crawling.csv', index = False, encoding = 'utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1R2JB64jeSp"
      },
      "source": [
        "# 2.2 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "oJhYUry3jeSq"
      },
      "source": [
        "df.loc[1]['content']  # 전처리 전"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SNdyknajeSq"
      },
      "source": [
        "[전처리]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "u-G0BITbjeSr"
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_white_space(text):\n",
        "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "def remove_special_char(text):\n",
        "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
        "    return text\n",
        "\n",
        "df.title = df.title.apply(remove_white_space)\n",
        "df.title = df.title.apply(remove_special_char)\n",
        "\n",
        "df.content = df.content.apply(remove_white_space)\n",
        "df.content = df.content.apply(remove_special_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xkDT5GIbjeSr"
      },
      "source": [
        "df.loc[1]['content']  # 전처리 후"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBvxzG_pjeSs"
      },
      "source": [
        "# 2.3 토크나이징 및 변수 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPA0xQPrjeSs"
      },
      "source": [
        "[토크나이징]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8AQMB2lgjeSs"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "df['title_token'] = df.title.apply(okt.morphs)\n",
        "df['content_token'] = df.content.apply(okt.nouns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcihvWFQjeSs"
      },
      "source": [
        "[파생변수 생성]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Ez_auqtojeSs"
      },
      "source": [
        "df['token_final'] = df.title_token + df.content_token\n",
        "\n",
        "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
        "\n",
        "print(df.dtypes)\n",
        "\n",
        "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DXf5h4fsjeSt"
      },
      "source": [
        "df_drop = df[['token_final', 'label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "aVlNoA19jeSv"
      },
      "source": [
        "df_drop.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_uOae1pjeSv"
      },
      "source": [
        "[데이터 엑셀로 저장]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wVoMV02EjeSv"
      },
      "source": [
        "df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnKKLHOxjeSw"
      },
      "source": [
        "# 2.4 단어 임베딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5R55CSojeSw"
      },
      "source": [
        "[단어 임베딩]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OKhp_DbdjeSw"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "embedding_model = Word2Vec(df_drop['token_final'], \n",
        "                           sg = 1, # skip-gram\n",
        "                           size = 100, \n",
        "                           window = 2, \n",
        "                           min_count = 1, \n",
        "                           workers = 4\n",
        "                           )\n",
        "\n",
        "print(embedding_model)\n",
        "\n",
        "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
        "print(model_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yTJhQeGjeSw"
      },
      "source": [
        "[임베딩 모델 저장 및 로드]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "pxMsCSCYjeSw"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v') # 모델 저장\n",
        "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v') # 모델 로드\n",
        "\n",
        "model_result = loaded_model.most_similar(\"음주운전\")\n",
        "print(model_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsJqzghLjeSx"
      },
      "source": [
        "# 2.5 실험 설계"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8WYjFEPjeSx"
      },
      "source": [
        "[데이터셋 분할 및 저장]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "w83-vYQyjeSx"
      },
      "source": [
        "from numpy.random import RandomState\n",
        "\n",
        "rng = RandomState()\n",
        "\n",
        "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
        "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
        "\n",
        "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
        "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CHrd-0SjeSx"
      },
      "source": [
        "[Field클래스 정의]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PtQrS1-5jeSx"
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
        "    text = text.split(', ')\n",
        "    return text\n",
        "\n",
        "TEXT = Field(tokenize=tokenizer)\n",
        "LABEL = Field(sequential = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKKrUUerjeSy"
      },
      "source": [
        "[데이터 불러오기]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "U1kOZUTAjeSy"
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "\n",
        "train, validation = TabularDataset.splits(\n",
        "    path = 'data/',\n",
        "    train = 'train.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format = 'csv',\n",
        "    fields = [('text', TEXT), ('label', LABEL)],\n",
        "    skip_header = True\n",
        ")\n",
        "\n",
        "print(\"Train:\", train[0].text,  train[0].label)\n",
        "print(\"Validation:\", validation[0].text, validation[0].label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYs09AoajeSy"
      },
      "source": [
        "[단어장 및 DataLoader 정의]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OPMvfAFejeSy"
      },
      "source": [
        "import torch\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.data import BucketIterator\n",
        "\n",
        "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
        "\n",
        "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
        "LABEL.build_vocab(train)\n",
        "\n",
        "vocab = TEXT.vocab\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_iter, validation_iter = BucketIterator.splits(\n",
        "    datasets = (train, validation),\n",
        "    batch_size = 8,\n",
        "    device = device,\n",
        "    sort = False\n",
        ")\n",
        "\n",
        "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTg50A1TjeSz"
      },
      "source": [
        "# 2.6 TextCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgfQlVB3jeSz"
      },
      "source": [
        "[TextCNN 모델링]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fJLrPnPbjeSz"
      },
      "source": [
        "import torch.nn as nn   \n",
        "import torch.optim as optim \n",
        "import torch.nn.functional as F \n",
        "\n",
        "class TextCNN(nn.Module): \n",
        "    \n",
        "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
        "        \n",
        "        super(TextCNN, self).__init__()\n",
        "        \n",
        "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
        "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
        "    \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
        "        self.relu = nn.ReLU()                \n",
        "        self.dropout = nn.Dropout(0.4)         \n",
        "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
        "        \n",
        "    def forward(self, x):  \n",
        "      \n",
        "        emb_x = self.embed(x)           \n",
        "        emb_x = emb_x.unsqueeze(1)  \n",
        "\n",
        "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
        "\n",
        "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
        "        \n",
        "        fc_x = torch.cat(pool_x, dim=1) \n",
        "        fc_x = fc_x.squeeze(-1)       \n",
        "        fc_x = self.dropout(fc_x)         \n",
        "\n",
        "        logit = self.fc(fc_x)     \n",
        "        \n",
        "        return logit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGy1fXAUjeSz"
      },
      "source": [
        "[모델 학습 함수 정의]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_V6tgnTdjeS0"
      },
      "source": [
        "def train(model, device, train_itr, optimizer):\n",
        "    \n",
        "    model.train()                               \n",
        "    corrects, train_loss = 0.0,0        \n",
        "    \n",
        "    for batch in train_itr:\n",
        "        \n",
        "        text, target = batch.text, batch.label      \n",
        "        text = torch.transpose(text, 0, 1)          \n",
        "        target.data.sub_(1)                                 \n",
        "        text, target = text.to(device), target.to(device)  \n",
        "\n",
        "        optimizer.zero_grad()                           \n",
        "        logit = model(text)                         \n",
        "    \n",
        "        loss = F.cross_entropy(logit, target)   \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        \n",
        "        train_loss += loss.item()    \n",
        "        result = torch.max(logit,1)[1] \n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "        \n",
        "    train_loss /= len(train_itr.dataset)\n",
        "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
        "\n",
        "    return train_loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPmdoFJ7jeS0"
      },
      "source": [
        "[모델 평가 함수 정의]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EyLxeRF8jeS0"
      },
      "source": [
        "def evaluate(model, device, itr):\n",
        "    \n",
        "    model.eval()\n",
        "    corrects, test_loss = 0.0, 0\n",
        "\n",
        "    for batch in itr:\n",
        "        \n",
        "        text = batch.text\n",
        "        target = batch.label\n",
        "        text = torch.transpose(text, 0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        \n",
        "        logit = model(text)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "        result = torch.max(logit,1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "\n",
        "    test_loss /= len(itr.dataset) \n",
        "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
        "    \n",
        "    return test_loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4bZHI4RjeS0"
      },
      "source": [
        "[모델 학습 및 성능 확인]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AqiKzpFUjeS0"
      },
      "source": [
        "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
        "print(model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "best_test_acc = -1\n",
        "\n",
        "for epoch in range(1, 3+1):\n",
        " \n",
        "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
        "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
        "    \n",
        "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
        "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
        "        \n",
        "    if val_acc > best_test_acc:\n",
        "        best_test_acc = val_acc\n",
        "        \n",
        "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
        "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
        "    \n",
        "    print('-----------------------------------------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}